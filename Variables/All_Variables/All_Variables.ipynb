{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Endogenous variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfdDNh266CQz"
      },
      "source": [
        "## NO - EA Inflation Core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbIKoniy3pLt",
        "outputId": "7eb680cd-cd73-469d-994d-7645c58d1bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norway core-HICP (TOT_X_NRG_FOOD) unit: I15\n",
            "Euro area HICP total (CP00) unit: I15\n",
            "            hicp_no_core  hicp_ea_all  p_no_core_log  p_ea_all_log\n",
            "time                                                              \n",
            "1999-12-01          79.9        75.09       4.380776      4.318687\n",
            "2000-01-01          79.7        75.13       4.378270      4.319220\n",
            "2000-02-01          80.1        75.37       4.383276      4.322409\n",
            "2000-03-01          80.3        75.60       4.385770      4.325456\n",
            "2000-04-01          80.8        75.67       4.391977      4.326382\n",
            "            hicp_no_core  hicp_ea_all  p_no_core_log  p_ea_all_log\n",
            "time                                                              \n",
            "2025-08-01         133.6       129.31       4.894850      4.862213\n",
            "2025-09-01         134.1       129.43       4.898586      4.863140\n",
            "2025-10-01         134.1       129.70       4.898586      4.865224\n",
            "2025-11-01         134.1       129.70       4.898586      4.865224\n",
            "2025-12-01         134.1       129.70       4.898586      4.865224\n",
            "Number of months: 313  | Period: 1999-12-01 → 2025-12-01\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io, gzip, re, requests\n",
        "\n",
        "\n",
        "URL = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/prc_hicp_midx?format=TSV&compressed=true\"\n",
        "\n",
        "r = requests.get(URL, timeout=120)\n",
        "r.raise_for_status()\n",
        "with gzip.open(io.BytesIO(r.content), 'rt') as f:\n",
        "    df_raw = pd.read_csv(f, sep='\\t')\n",
        "\n",
        "# Split the dimension column: 'freq,unit,coicop,geo\\\\TIME_PERIOD'\n",
        "dimcol = df_raw.columns[0]\n",
        "df_raw[['freq','unit','coicop','geo']] = df_raw[dimcol].str.split(',', expand=True)\n",
        "df_raw = df_raw.drop(columns=[dimcol])\n",
        "\n",
        "# Identify time columns (YYYY-MM with optional trailing space)\n",
        "time_cols = [c for c in df_raw.columns if re.match(r'^\\d{4}-\\d{2}\\s*$', c)]\n",
        "df_long = df_raw.melt(\n",
        "    id_vars=['freq','unit','coicop','geo'],\n",
        "    value_vars=time_cols,\n",
        "    var_name='time',\n",
        "    value_name='value'\n",
        ")\n",
        "\n",
        "# Clean values: remove ':' and keep numeric values only\n",
        "df_long['value'] = df_long['value'].astype(str).str.strip()\n",
        "df_long = df_long[(df_long['value'] != ':') & (df_long['value'] != '')]\n",
        "num = df_long['value'].str.extract(r'^\\s*([-]?\\d+(?:\\.\\d+)?)')\n",
        "df_long = df_long[~num[0].isna()].copy()\n",
        "df_long['value'] = num[0].astype(float)\n",
        "\n",
        "# Standardize time format\n",
        "df_long['time'] = df_long['time'].str.strip()\n",
        "df_long['time'] = pd.to_datetime(df_long['time'], format=\"%Y-%m\", errors='coerce')\n",
        "df_long = df_long.dropna(subset=['time'])\n",
        "\n",
        "# Helper functions\n",
        "def best_unit(df, prefer=('I15','I05','I96')):\n",
        "    units = df['unit'].dropna().unique().tolist()\n",
        "    for u in prefer:\n",
        "        if u in units:\n",
        "            return u\n",
        "    return units[0] if units else None\n",
        "\n",
        "def get_series(df, geo, coicop, start_year=1999, end_year=2025):\n",
        "    sub = df.query(\"geo == @geo and coicop == @coicop\").copy()\n",
        "    if sub.empty:\n",
        "        raise ValueError(f\"No rows found for geo={geo}, coicop={coicop}\")\n",
        "    u = best_unit(sub)\n",
        "    sub = sub[sub['unit'] == u].copy()\n",
        "    sub = sub[(sub['time'].dt.year >= start_year) & (sub['time'].dt.year <= end_year)]\n",
        "    sub = sub.sort_values('time').reset_index(drop=True)\n",
        "    return sub[['time','value']].assign(unit=u)\n",
        "\n",
        "# Extract HICP series\n",
        "no_core = get_series(df_long, geo='NO', coicop='TOT_X_NRG_FOOD', start_year=1999, end_year=2025)\n",
        "print(f\"Norway core-HICP (TOT_X_NRG_FOOD) unit: {no_core['unit'].iloc[0]}\")\n",
        "\n",
        "ea_all = get_series(df_long, geo='EA', coicop='CP00', start_year=1999, end_year=2025)\n",
        "print(f\"Euro area HICP total (CP00) unit: {ea_all['unit'].iloc[0]}\")\n",
        "\n",
        "# Build complete monthly range and forward-fill\n",
        "full_index = pd.date_range(start=\"1999-12-01\", end=\"2025-12-01\", freq=\"MS\")\n",
        "\n",
        "df = full_index.to_frame(name=\"time\")\n",
        "df = df.merge(no_core[['time','value']].rename(columns={'value':'hicp_no_core'}), on='time', how='left')\n",
        "df = df.merge(ea_all[['time','value']].rename(columns={'value':'hicp_ea_all'}), on='time', how='left')\n",
        "df[['hicp_no_core','hicp_ea_all']] = df[['hicp_no_core','hicp_ea_all']].ffill()\n",
        "\n",
        "# Log transforms\n",
        "df['p_no_core_log'] = np.log(df['hicp_no_core'])\n",
        "df['p_ea_all_log']  = np.log(df['hicp_ea_all'])\n",
        "\n",
        "# Final monthly dataset\n",
        "out = df[['time', 'hicp_no_core', 'hicp_ea_all', 'p_no_core_log', 'p_ea_all_log']].copy()\n",
        "out = out.set_index('time')\n",
        "out.index.freq = 'MS'\n",
        "\n",
        "print(out.head(5))\n",
        "print(out.tail(5))\n",
        "print(f\"Number of months: {len(out)}  | Period: {out.index.min().date()} → {out.index.max().date()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99aZz9Z76As7"
      },
      "source": [
        "## EU NOK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWlO0n1D5_3c",
        "outputId": "1d273435-be8a-48d4-c1f8-eb24dfa478b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            EUR_NOK\n",
            "DATE               \n",
            "2000-01-03   8.0620\n",
            "2000-01-04   8.1500\n",
            "2000-01-05   8.2060\n",
            "2000-01-06   8.2030\n",
            "2000-01-07   8.1945\n",
            "2000-01-08   8.1945\n",
            "2000-01-09   8.1945\n",
            "2000-01-10   8.1900\n",
            "2000-01-11   8.2075\n",
            "2000-01-12   8.2160\n",
            "            EUR_NOK\n",
            "DATE               \n",
            "2025-10-27  11.6320\n",
            "2025-10-28  11.6335\n",
            "2025-10-29  11.6385\n",
            "2025-10-30  11.6648\n",
            "2025-10-31  11.6485\n",
            "2025-11-01  11.6485\n",
            "2025-11-02  11.6485\n",
            "2025-11-03  11.6480\n",
            "2025-11-04  11.7265\n",
            "2025-11-05  11.7490\n",
            "\n",
            "Number of days: 9439  | Period: 2000-01-03 → 2025-11-05\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Download data from Norges Bank (2000–2025) \n",
        "url = (\"https://data.norges-bank.no/api/data/EXR/B.EUR.NOK.SP\"\n",
        "       \"?format=csv&bom=include&apisrc=nbi\"\n",
        "       \"&startPeriod=2000-01-01&endPeriod=2025-12-31&locale=no\")\n",
        "\n",
        "# Read CSV (semicolon separator, comma as decimal)\n",
        "df = pd.read_csv(url, sep=';', encoding='utf-8-sig', decimal=',')\n",
        "\n",
        "# 2) Select date and exchange rate columns \n",
        "# Handles potential column name variations (e.g. OBS_VALUE_N)\n",
        "value_col = 'OBS_VALUE' if 'OBS_VALUE' in df.columns else 'OBS_VALUE_N'\n",
        "df = (\n",
        "    df[['TIME_PERIOD', value_col]]\n",
        "      .rename(columns={'TIME_PERIOD': 'DATE', value_col: 'EUR_NOK'})\n",
        ")\n",
        "\n",
        "df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')\n",
        "df = df.dropna(subset=['DATE','EUR_NOK']).sort_values('DATE').set_index('DATE')\n",
        "\n",
        "# 3) Create full daily index and forward-fill missing values \n",
        "full_idx = pd.date_range(df.index.min(), df.index.max(), freq='D')\n",
        "df_daily = df.reindex(full_idx)\n",
        "\n",
        "df_daily['EUR_NOK'] = df_daily['EUR_NOK'].ffill()\n",
        "df_daily.index.name = 'DATE'\n",
        "df_daily = df_daily.asfreq('D')\n",
        "\n",
        "# 4) Inspect output \n",
        "print(df_daily.head(10))\n",
        "print(df_daily.tail(10))\n",
        "print(f\"\\nNumber of days: {len(df_daily)}  | Period: {df_daily.index.min().date()} → {df_daily.index.max().date()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjv4PbgE6WbA"
      },
      "source": [
        "## Merge EU/NOK price with Inflation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mG0salU6aKG",
        "outputId": "0bf70e90-9a39-42be-cdbe-14799ab71bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            EUR_NOK  hicp_no_core  hicp_ea_all  p_no_core_log  p_ea_all_log  \\\n",
            "DATE                                                                          \n",
            "2000-01-03   8.0620          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-04   8.1500          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-05   8.2060          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-06   8.2030          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-07   8.1945          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-08   8.1945          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-09   8.1945          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-10   8.1900          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-11   8.2075          79.7        75.13        4.37827       4.31922   \n",
            "2000-01-12   8.2160          79.7        75.13        4.37827       4.31922   \n",
            "\n",
            "            s_eurnok_log  \n",
            "DATE                      \n",
            "2000-01-03      2.087162  \n",
            "2000-01-04      2.098018  \n",
            "2000-01-05      2.104866  \n",
            "2000-01-06      2.104500  \n",
            "2000-01-07      2.103463  \n",
            "2000-01-08      2.103463  \n",
            "2000-01-09      2.103463  \n",
            "2000-01-10      2.102914  \n",
            "2000-01-11      2.105048  \n",
            "2000-01-12      2.106083  \n",
            "            EUR_NOK  hicp_no_core  hicp_ea_all  p_no_core_log  p_ea_all_log  \\\n",
            "DATE                                                                          \n",
            "2025-10-27  11.6320         134.1        129.7       4.898586      4.865224   \n",
            "2025-10-28  11.6335         134.1        129.7       4.898586      4.865224   \n",
            "2025-10-29  11.6385         134.1        129.7       4.898586      4.865224   \n",
            "2025-10-30  11.6648         134.1        129.7       4.898586      4.865224   \n",
            "2025-10-31  11.6485         134.1        129.7       4.898586      4.865224   \n",
            "2025-11-01  11.6485         134.1        129.7       4.898586      4.865224   \n",
            "2025-11-02  11.6485         134.1        129.7       4.898586      4.865224   \n",
            "2025-11-03  11.6480         134.1        129.7       4.898586      4.865224   \n",
            "2025-11-04  11.7265         134.1        129.7       4.898586      4.865224   \n",
            "2025-11-05  11.7490         134.1        129.7       4.898586      4.865224   \n",
            "\n",
            "            s_eurnok_log  \n",
            "DATE                      \n",
            "2025-10-27      2.453760  \n",
            "2025-10-28      2.453889  \n",
            "2025-10-29      2.454319  \n",
            "2025-10-30      2.456576  \n",
            "2025-10-31      2.455177  \n",
            "2025-11-01      2.455177  \n",
            "2025-11-02      2.455177  \n",
            "2025-11-03      2.455134  \n",
            "2025-11-04      2.461851  \n",
            "2025-11-05      2.463768  \n",
            "\n",
            "Number of days: 9439 | Period: 2000-01-03 → 2025-11-05\n"
          ]
        }
      ],
      "source": [
        "# 1) Convert HICP (out) to daily frequency using forward-fill \n",
        "# Start and end dates are defined from 'out'\n",
        "daily_idx = pd.date_range(start=out.index.min(), end=out.index.max(), freq='D')\n",
        "\n",
        "out_daily = (\n",
        "    out.reindex(daily_idx)     # add all daily timestamps\n",
        "       .ffill()                # keep the last monthly value until a new month begins\n",
        ")\n",
        "\n",
        "out_daily.index.name = 'DATE'\n",
        "\n",
        "# 2) Merge with Norges Bank daily data (df_daily) \n",
        "merged = (\n",
        "    df_daily[['EUR_NOK']]\n",
        "    .merge(out_daily, left_index=True, right_index=True, how='left')\n",
        ")\n",
        "\n",
        "# 3) Add log of the exchange rate \n",
        "merged['s_eurnok_log'] = np.log(merged['EUR_NOK'])\n",
        "\n",
        "# 4) Inspect output \n",
        "print(merged.head(10))\n",
        "print(merged.tail(10))\n",
        "print(f\"\\nNumber of days: {len(merged)} | Period: {merged.index.min().date()} → {merged.index.max().date()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A2gCOdQ7AJ9"
      },
      "source": [
        "## Reell valutakurs (q) & Inflasjonsdifferanse (dπ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee6PJ3w78p_Z",
        "outputId": "ea9528c0-6502-4a16-861d-3f4d03405429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            EUR_NOK  hicp_no_core  hicp_ea_all        st        pt   pt_star  \\\n",
            "DATE                                                                           \n",
            "2000-01-31   8.0825          79.7        75.13  2.089701  4.378270  4.319220   \n",
            "2000-02-01   8.0730          80.1        75.37  2.088525  4.383276  4.322409   \n",
            "2000-02-02   8.0175          80.1        75.37  2.081627  4.383276  4.322409   \n",
            "2000-02-03   8.0475          80.1        75.37  2.085361  4.383276  4.322409   \n",
            "2000-02-04   8.0830          80.1        75.37  2.089763  4.383276  4.322409   \n",
            "2000-02-05   8.0830          80.1        75.37  2.089763  4.383276  4.322409   \n",
            "2000-02-06   8.0830          80.1        75.37  2.089763  4.383276  4.322409   \n",
            "2000-02-07   8.0590          80.1        75.37  2.086789  4.383276  4.322409   \n",
            "2000-02-08   8.0720          80.1        75.37  2.088401  4.383276  4.322409   \n",
            "2000-02-09   8.0825          80.1        75.37  2.089701  4.383276  4.322409   \n",
            "2000-02-10   8.0695          80.1        75.37  2.088092  4.383276  4.322409   \n",
            "2000-02-11   8.0395          80.1        75.37  2.084367  4.383276  4.322409   \n",
            "\n",
            "                  qt      pi_t  pi_t_star     dpi_t  \n",
            "DATE                                                 \n",
            "2000-01-31  2.030652  0.005006   0.003189  0.001817  \n",
            "2000-02-01  2.027659  0.005006   0.003189  0.001817  \n",
            "2000-02-02  2.020760  0.005006   0.003189  0.001817  \n",
            "2000-02-03  2.024495  0.005006   0.003189  0.001817  \n",
            "2000-02-04  2.028897  0.005006   0.003189  0.001817  \n",
            "2000-02-05  2.028897  0.005006   0.003189  0.001817  \n",
            "2000-02-06  2.028897  0.005006   0.003189  0.001817  \n",
            "2000-02-07  2.025923  0.005006   0.003189  0.001817  \n",
            "2000-02-08  2.027535  0.005006   0.003189  0.001817  \n",
            "2000-02-09  2.028835  0.005006   0.003189  0.001817  \n",
            "2000-02-10  2.027225  0.005006   0.003189  0.001817  \n",
            "2000-02-11  2.023500  0.005006   0.003189  0.001817  \n",
            "            EUR_NOK  hicp_no_core  hicp_ea_all        st        pt   pt_star  \\\n",
            "DATE                                                                           \n",
            "2025-10-25  11.6185         134.1        129.7  2.452599  4.898586  4.865224   \n",
            "2025-10-26  11.6185         134.1        129.7  2.452599  4.898586  4.865224   \n",
            "2025-10-27  11.6320         134.1        129.7  2.453760  4.898586  4.865224   \n",
            "2025-10-28  11.6335         134.1        129.7  2.453889  4.898586  4.865224   \n",
            "2025-10-29  11.6385         134.1        129.7  2.454319  4.898586  4.865224   \n",
            "2025-10-30  11.6648         134.1        129.7  2.456576  4.898586  4.865224   \n",
            "2025-10-31  11.6485         134.1        129.7  2.455177  4.898586  4.865224   \n",
            "2025-11-01  11.6485         134.1        129.7  2.455177  4.898586  4.865224   \n",
            "2025-11-02  11.6485         134.1        129.7  2.455177  4.898586  4.865224   \n",
            "2025-11-03  11.6480         134.1        129.7  2.455134  4.898586  4.865224   \n",
            "2025-11-04  11.7265         134.1        129.7  2.461851  4.898586  4.865224   \n",
            "2025-11-05  11.7490         134.1        129.7  2.463768  4.898586  4.865224   \n",
            "\n",
            "                  qt  pi_t  pi_t_star     dpi_t  \n",
            "DATE                                             \n",
            "2025-10-25  2.419237   0.0   0.002084 -0.002084  \n",
            "2025-10-26  2.419237   0.0   0.002084 -0.002084  \n",
            "2025-10-27  2.420398   0.0   0.002084 -0.002084  \n",
            "2025-10-28  2.420527   0.0   0.002084 -0.002084  \n",
            "2025-10-29  2.420957   0.0   0.002084 -0.002084  \n",
            "2025-10-30  2.423214   0.0   0.002084 -0.002084  \n",
            "2025-10-31  2.421816   0.0   0.002084 -0.002084  \n",
            "2025-11-01  2.421816   0.0   0.000000  0.000000  \n",
            "2025-11-02  2.421816   0.0   0.000000  0.000000  \n",
            "2025-11-03  2.421773   0.0   0.000000  0.000000  \n",
            "2025-11-04  2.428490   0.0   0.000000  0.000000  \n",
            "2025-11-05  2.430406   0.0   0.000000  0.000000  \n",
            "\n",
            "Number of days (original): 9439 | Period: 2000-01-03 → 2025-11-05\n",
            "Number of days (after NaN removal): 9411\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1) Convert HICP (out) to daily frequency using forward-fill \n",
        "daily_idx = pd.date_range(start=out.index.min(), end=out.index.max(), freq='D')\n",
        "out_daily = (\n",
        "    out.reindex(daily_idx)      # add all daily dates\n",
        "       .ffill()                 # keep the last monthly value until next month\n",
        ")\n",
        "out_daily.index.name = 'DATE'\n",
        "\n",
        "# 2) Merge with Norges Bank daily data (df_daily) \n",
        "merged = (\n",
        "    df_daily[['EUR_NOK']]\n",
        "    .merge(out_daily, left_index=True, right_index=True, how='left')\n",
        ")\n",
        "\n",
        "# 3) Daily log levels and real exchange rate \n",
        "merged['st'] = np.log(merged['EUR_NOK'])                # log(EUR/NOK)\n",
        "merged['pt'] = np.log(merged['hicp_no_core'])           # Norway price level\n",
        "merged['pt_star'] = np.log(merged['hicp_ea_all'])       # Euro area price level\n",
        "merged['qt'] = merged['st'] - (merged['pt'] - merged['pt_star'])  # real exchange rate\n",
        "\n",
        "# 4) Month-to-month inflation (Δlog) at month-end, mapped to daily within same month \n",
        "no_me = merged['hicp_no_core'].resample('M').last()\n",
        "ea_me = merged['hicp_ea_all'].resample('M').last()\n",
        "\n",
        "p_no_me = np.log(no_me)\n",
        "p_ea_me = np.log(ea_me)\n",
        "pi_no_m = p_no_me.diff(1)          # π_t  (Norway)\n",
        "pi_ea_m = p_ea_me.diff(1)          # π_t* (Euro area)\n",
        "dpi_m   = pi_no_m - pi_ea_m        # inflation differential\n",
        "\n",
        "# Map monthly values to daily so that the same value holds for the entire month\n",
        "didx   = merged.index\n",
        "end_me = didx.max() + pd.offsets.MonthEnd(0)\n",
        "drng   = pd.date_range(pi_no_m.index.min(), end_me, freq='D')\n",
        "\n",
        "def to_daily_same_month(s, daily_index):\n",
        "    daily_full = s.reindex(drng).bfill()  # backfill to fill same month\n",
        "    return daily_full.reindex(daily_index)\n",
        "\n",
        "merged['pi_t']      = to_daily_same_month(pi_no_m, didx)\n",
        "merged['pi_t_star'] = to_daily_same_month(pi_ea_m, didx)\n",
        "merged['dpi_t']     = to_daily_same_month(dpi_m, didx)\n",
        "\n",
        "# 5) Clean for model use \n",
        "needed_cols = [\n",
        "    'EUR_NOK', 'hicp_no_core', 'hicp_ea_all',\n",
        "    'st', 'pt', 'pt_star', 'qt',\n",
        "    'pi_t', 'pi_t_star', 'dpi_t'\n",
        "]\n",
        "final_df = merged.dropna(subset=needed_cols).copy()\n",
        "\n",
        "# 6) Display summary \n",
        "print(final_df[needed_cols].head(12))\n",
        "print(final_df[needed_cols].tail(12))\n",
        "print(f\"\\nNumber of days (original): {len(merged)} | Period: {merged.index.min().date()} → {merged.index.max().date()}\")\n",
        "print(f\"Number of days (after NaN removal): {len(final_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNBmLjY7Gqsc",
        "outputId": "3d627ef2-3154-41db-f9e9-e12c9e6c2c8f"
      },
      "outputs": [],
      "source": [
        "# EUR/NOK, Q, and d_pi only \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Q = real exchange rate = s_t - (p_t - p_t*)\n",
        "merged['st']      = np.log(merged['EUR_NOK'])          # s_t\n",
        "merged['pt']      = np.log(merged['hicp_no_core'])     # p_t\n",
        "merged['pt_star'] = np.log(merged['hicp_ea_all'])      # p_t*\n",
        "merged['Q']       = merged['st'] - (merged['pt'] - merged['pt_star'])\n",
        "\n",
        "# 2) d_pi = inflation differential = π_t - π_t*\n",
        "#    (Δlog of end-of-month levels, mapped to daily within the same month)\n",
        "no_me = merged['hicp_no_core'].resample('M').last()\n",
        "ea_me = merged['hicp_ea_all'].resample('M').last()\n",
        "\n",
        "pi_no_m = np.log(no_me).diff(1)\n",
        "pi_ea_m = np.log(ea_me).diff(1)\n",
        "d_pi_m  = pi_no_m - pi_ea_m\n",
        "\n",
        "# Map to daily frequency: backfill from month-end so value holds for the same month\n",
        "didx   = merged.index\n",
        "end_me = didx.max() + pd.offsets.MonthEnd(0)\n",
        "drng   = pd.date_range(d_pi_m.index.min(), end_me, freq='D')\n",
        "\n",
        "d_pi_daily = d_pi_m.reindex(drng).bfill().reindex(didx)\n",
        "merged['d_pi'] = d_pi_daily\n",
        "\n",
        "# 3) Final dataset for model\n",
        "final_small = merged[['EUR_NOK', 'Q', 'd_pi']].dropna().copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvXxouuqHY0W"
      },
      "source": [
        "## Rentedifferanse (dI_t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norges Bank policy rate:\n",
            "            policy_rate\n",
            "DATE                   \n",
            "2000-01-01          5.5\n",
            "2000-01-02          5.5\n",
            "2000-01-03          5.5\n",
            "            policy_rate\n",
            "DATE                   \n",
            "2025-12-29          4.0\n",
            "2025-12-30          4.0\n",
            "2025-12-31          4.0\n",
            "Period: 2000-01-01 → 2025-12-31\n",
            "\n",
            "Interest rate differential sample:\n",
            "            NO_rate  EA_rate  dI_t\n",
            "DATE                              \n",
            "2000-01-01      5.5     3.75  1.75\n",
            "2000-01-02      5.5     3.75  1.75\n",
            "2000-01-03      5.5     3.75  1.75\n",
            "2000-01-04      5.5     3.75  1.75\n",
            "2000-01-05      5.5     3.75  1.75\n",
            "            NO_rate  EA_rate  dI_t\n",
            "DATE                              \n",
            "2025-12-27      4.0      2.0   2.0\n",
            "2025-12-28      4.0      2.0   2.0\n",
            "2025-12-29      4.0      2.0   2.0\n",
            "2025-12-30      4.0      2.0   2.0\n",
            "2025-12-31      4.0      2.0   2.0\n",
            "Coverage: 2000-01-01 → 2025-12-31 | NaNs: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, numpy as np, re, requests\n",
        "import io, requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 1) NORWAY POLICY RATE (Norges Bank)\n",
        "\n",
        "url_nb = (\n",
        "    \"https://data.norges-bank.no/api/data/IR/B.KPRA.SD.R\"\n",
        "    \"?apisrc=qb&format=csv&startPeriod=1996-01-01&endPeriod=2025-09-26&locale=no&bom=include\"\n",
        ")\n",
        "\n",
        "df_rate_nb = pd.read_csv(url_nb, sep=\";\", encoding=\"utf-8-sig\", engine=\"python\")\n",
        "df_rate_nb.columns = [c.strip() for c in df_rate_nb.columns]\n",
        "\n",
        "time_candidates  = [\"TIME_PERIOD\", \"Tid\", \"TIME\", \"Date\", \"PERIOD\"]\n",
        "value_candidates = [\"OBS_VALUE\", \"Observasjonsverdi\", \"Value\", \"VALUE\"]\n",
        "time_col  = next((c for c in time_candidates  if c in df_rate_nb.columns), None)\n",
        "value_col = next((c for c in value_candidates if c in df_rate_nb.columns), None)\n",
        "\n",
        "rate_nb = (\n",
        "    df_rate_nb[[time_col, value_col]]\n",
        "    .rename(columns={time_col: \"DATE\", value_col: \"policy_rate\"})\n",
        ")\n",
        "rate_nb[\"policy_rate\"] = pd.to_numeric(rate_nb[\"policy_rate\"].astype(str).str.replace(\",\", \".\"), errors=\"coerce\")\n",
        "rate_nb[\"DATE\"] = pd.to_datetime(rate_nb[\"DATE\"], errors=\"coerce\")\n",
        "rate_nb = rate_nb.dropna(subset=[\"DATE\", \"policy_rate\"]).sort_values(\"DATE\").set_index(\"DATE\")\n",
        "\n",
        "# Daily reindex full range\n",
        "policy_rate_daily = rate_nb.reindex(pd.date_range(\"2000-01-01\", \"2025-12-31\", freq=\"D\")).ffill().bfill()\n",
        "policy_rate_daily.index.name = \"DATE\"\n",
        "\n",
        "print(\"Norges Bank policy rate:\")\n",
        "print(policy_rate_daily.head(3))\n",
        "print(policy_rate_daily.tail(3))\n",
        "print(f\"Period: {policy_rate_daily.index.min().date()} → {policy_rate_daily.index.max().date()}\\n\")\n",
        "\n",
        "# 2) ECB POLICY RATE (Deposit Facility) – SDW API\n",
        "\n",
        "URL = \"https://www.ecb.europa.eu/stats/policy_and_exchange_rates/key_ecb_interest_rates/html/index.en.html\"\n",
        "html = requests.get(URL, timeout=30).text\n",
        "soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "table = None\n",
        "for tbl in soup.find_all(\"table\"):\n",
        "    if tbl.find(string=re.compile(\"Date \\\\(with effect from\\\\)\", re.I)):\n",
        "        table = tbl\n",
        "        break\n",
        "if table is None:\n",
        "    raise RuntimeError(\"ECB table not found\")\n",
        "\n",
        "rows, year = [], None\n",
        "for tr in table.find_all(\"tr\"):\n",
        "    tds = [td.get_text(\" \", strip=True) for td in tr.find_all([\"td\",\"th\"])]\n",
        "    if not tds or \"Date\" in tds[0]:\n",
        "        continue\n",
        "    if re.fullmatch(r\"\\d{4}\", tds[0]):\n",
        "        year = tds[0]\n",
        "        date_str, dep = tds[1], tds[2]\n",
        "    else:\n",
        "        date_str, dep = tds[0], tds[1] if len(tds)>1 else \"-\"\n",
        "    m = re.search(r\"(\\d{1,2})\\s+([A-Za-z]{3})\", date_str)\n",
        "    if not m:\n",
        "        continue\n",
        "    d = f\"{m.group(1)} {m.group(2)} {year}\"\n",
        "    d_iso = pd.to_datetime(d, format=\"%d %b %Y\", errors=\"coerce\")\n",
        "    val = pd.to_numeric(dep.replace(\",\", \".\"), errors=\"coerce\")\n",
        "    if pd.notna(d_iso) and pd.notna(val):\n",
        "        rows.append({\"DATE\": d_iso, \"eu_policy_rate\": val})\n",
        "\n",
        "ecb_rate_daily = (\n",
        "    pd.DataFrame(rows)\n",
        "      .dropna(subset=[\"DATE\"])\n",
        "      .set_index(\"DATE\")\n",
        "      .sort_index()\n",
        "      .reindex(pd.date_range(\"2000-01-01\", \"2025-12-31\", freq=\"D\"))\n",
        "      .ffill().bfill()\n",
        ")\n",
        "ecb_rate_daily.index.name = \"DATE\"\n",
        "\n",
        "\n",
        "# 3) INTEREST RATE DIFFERENTIAL (Norway – Euro area)\n",
        "\n",
        "common_idx = pd.date_range(\n",
        "    start=max(policy_rate_daily.index.min(), ecb_rate_daily.index.min()),\n",
        "    end=min(policy_rate_daily.index.max(), ecb_rate_daily.index.max()),\n",
        "    freq=\"D\"\n",
        ")\n",
        "\n",
        "rates = pd.DataFrame({\n",
        "    \"NO_rate\": policy_rate_daily.reindex(common_idx).ffill().bfill()[\"policy_rate\"],\n",
        "    \"EA_rate\": ecb_rate_daily.reindex(common_idx).ffill().bfill()[\"eu_policy_rate\"],\n",
        "})\n",
        "rates[\"dI_t\"] = rates[\"NO_rate\"] - rates[\"EA_rate\"]\n",
        "rates.index.name = \"DATE\"\n",
        "\n",
        "print(\"Interest rate differential sample:\")\n",
        "print(rates.head(5))\n",
        "print(rates.tail(5))\n",
        "print(f\"Coverage: {rates.index.min().date()} → {rates.index.max().date()} | NaNs: {rates['dI_t'].isna().sum()}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Daily Endegenous "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final daily dataset:\n",
            "            EUR_NOK         Q      d_pi  dI_t\n",
            "DATE                                         \n",
            "2000-01-31   8.0825  2.030652  0.001817  1.75\n",
            "2000-02-01   8.0730  2.027659  0.001817  1.75\n",
            "2000-02-02   8.0175  2.020760  0.001817  1.75\n",
            "2000-02-03   8.0475  2.024495  0.001817  1.75\n",
            "2000-02-04   8.0830  2.028897  0.001817  1.75\n",
            "2000-02-05   8.0830  2.028897  0.001817  1.75\n",
            "2000-02-06   8.0830  2.028897  0.001817  1.75\n",
            "2000-02-07   8.0590  2.025923  0.001817  1.75\n",
            "2000-02-08   8.0720  2.027535  0.001817  1.75\n",
            "2000-02-09   8.0825  2.028835  0.001817  1.75\n",
            "            EUR_NOK         Q      d_pi  dI_t\n",
            "DATE                                         \n",
            "2025-10-27  11.6320  2.420398 -0.002084   2.0\n",
            "2025-10-28  11.6335  2.420527 -0.002084   2.0\n",
            "2025-10-29  11.6385  2.420957 -0.002084   2.0\n",
            "2025-10-30  11.6648  2.423214 -0.002084   2.0\n",
            "2025-10-31  11.6485  2.421816 -0.002084   2.0\n",
            "2025-11-01  11.6485  2.421816  0.000000   2.0\n",
            "2025-11-02  11.6485  2.421816  0.000000   2.0\n",
            "2025-11-03  11.6480  2.421773  0.000000   2.0\n",
            "2025-11-04  11.7265  2.428490  0.000000   2.0\n",
            "2025-11-05  11.7490  2.430406  0.000000   2.0\n",
            "\n",
            "Final dataset: 9411 obs | Period: 2000-01-31 → 2025-11-05\n",
            "\n",
            "Saved successfully as 'variables_daily_end.csv'\n"
          ]
        }
      ],
      "source": [
        "final_with_rates = (\n",
        "    final_small\n",
        "    .merge(rates[[\"dI_t\"]], left_index=True, right_index=True, how=\"left\")\n",
        "    .dropna(subset=[\"dI_t\"])\n",
        ")\n",
        "final_with_rates = final_with_rates[[\"EUR_NOK\", \"Q\", \"d_pi\", \"dI_t\"]]\n",
        "\n",
        "print(\"Final daily dataset:\")\n",
        "print(final_with_rates.head(10))\n",
        "print(final_with_rates.tail(10))\n",
        "print(f\"\\nFinal dataset: {len(final_with_rates)} obs | \"\n",
        "      f\"Period: {final_with_rates.index.min().date()} → {final_with_rates.index.max().date()}\")\n",
        "\n",
        "# Save to CSV \n",
        "final_with_rates.index.name = \"DATE\"\n",
        "final_with_rates.to_csv(\"variables_daily_end.csv\", index=True, float_format=\"%.6f\")\n",
        "print(\"\\nSaved successfully as 'variables_daily_end.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxZk-NCZKlgU"
      },
      "source": [
        "## Monthly Endogenous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5a49DSgKk3U",
        "outputId": "2fd8eaab-460f-4fc8-aa5a-cf576100dc05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monthly endogenous dataset:\n",
            "            EUR_NOK         Q      d_pi  dI_t\n",
            "DATE                                         \n",
            "2000-01-31   8.0825  2.030652  0.001817  1.75\n",
            "2000-02-29   8.0805  2.028587  0.001817  1.75\n",
            "2000-03-31   8.0885  2.030130 -0.000553  1.75\n",
            "2000-04-30   8.1475  2.032116  0.005282  2.00\n",
            "2000-05-31   8.3050  2.052451 -0.001189  2.00\n",
            "2000-06-30   8.1850  2.037880  0.000017  2.50\n",
            "2000-07-31   8.1990  2.044609 -0.005020  2.50\n",
            "2000-08-31   8.0745  2.030095 -0.000788  3.00\n",
            "2000-09-30   8.0255  2.020539  0.003469  3.25\n",
            "2000-10-31   7.8735  2.001680 -0.000261  3.25\n",
            "2000-11-30   8.0525  2.023794  0.000365  3.25\n",
            "2000-12-31   8.2335  2.050894 -0.004871  3.25\n",
            "            EUR_NOK         Q      d_pi  dI_t\n",
            "DATE                                         \n",
            "2024-12-31  11.7950  2.431128 -0.000508  1.50\n",
            "2025-01-31  11.7373  2.430318 -0.004094  1.50\n",
            "2025-02-28  11.7245  2.423597  0.005630  1.75\n",
            "2025-03-31  11.4130  2.399005 -0.002335  2.00\n",
            "2025-04-30  11.8090  2.429050  0.004064  2.25\n",
            "2025-05-31  11.5408  2.407774 -0.001698  2.25\n",
            "2025-06-30  11.8345  2.430786  0.002119  2.25\n",
            "2025-07-31  11.7740  2.424328  0.001332  2.25\n",
            "2025-08-31  11.7465  2.430918 -0.008928  2.25\n",
            "2025-09-30  11.7265  2.426406  0.002808  2.00\n",
            "2025-10-31  11.6485  2.421816 -0.002084  2.00\n",
            "2025-11-30  11.7490  2.430406  0.000000  2.00\n",
            "\n",
            "Total rows (monthly): 311 | Period: 2000-01-31 → 2025-11-30\n"
          ]
        }
      ],
      "source": [
        "# 1) Ensure index is datetime and sorted\n",
        "final_with_rates = final_with_rates.sort_index()\n",
        "final_with_rates.index = pd.to_datetime(final_with_rates.index)\n",
        "\n",
        "# 2) Aggregate to month-end ('M') using LAST observation\n",
        "final_monthly = pd.DataFrame({\n",
        "    \"EUR_NOK\": final_with_rates[\"EUR_NOK\"].resample(\"M\").last(),   # nominal exchange rate (level)\n",
        "    \"Q\":       final_with_rates[\"Q\"].resample(\"M\").last(),         # real exchange rate (level)\n",
        "    \"d_pi\":    final_with_rates[\"d_pi\"].resample(\"M\").last(),      # inflation differential (monthly)\n",
        "    \"dI_t\":    final_with_rates[\"dI_t\"].resample(\"M\").last(),      # interest rate differential (level)\n",
        "})\n",
        "\n",
        "# 3) Drop potential NaN rows (alignment)\n",
        "final_monthly = final_monthly.dropna(how=\"any\")\n",
        "\n",
        "# 4) Assign proper monthly frequency\n",
        "final_monthly.index.name = \"DATE\"\n",
        "final_monthly = final_monthly.asfreq(\"M\")\n",
        "\n",
        "# 5) Inspect results\n",
        "print(\"Monthly endogenous dataset:\")\n",
        "print(final_monthly.head(12))\n",
        "print(final_monthly.tail(12))\n",
        "print(f\"\\nTotal rows (monthly): {len(final_monthly)} | \"\n",
        "      f\"Period: {final_monthly.index.min().date()} → {final_monthly.index.max().date()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMJ2XjRUOrOF"
      },
      "source": [
        "# Exogenous Variables "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vJKpbBtOto7"
      },
      "source": [
        "## VIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Ouo17XOuq0",
        "outputId": "db3f90f4-9d5e-43ae-9fe1-04788c832341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              VIX\n",
            "DATE             \n",
            "2000-01-03  24.21\n",
            "2000-01-04  27.01\n",
            "2000-01-05  26.41\n",
            "2000-01-06  25.73\n",
            "2000-01-07  21.72\n",
            "2000-01-08  21.72\n",
            "2000-01-09  21.72\n",
            "2000-01-10  21.71\n",
            "2000-01-11  22.50\n",
            "2000-01-12  22.84\n",
            "              VIX\n",
            "DATE             \n",
            "2025-10-27  15.79\n",
            "2025-10-28  16.42\n",
            "2025-10-29  16.92\n",
            "2025-10-30  16.91\n",
            "2025-10-31  17.44\n",
            "2025-11-01  17.44\n",
            "2025-11-02  17.44\n",
            "2025-11-03  17.17\n",
            "2025-11-04  19.00\n",
            "2025-11-05  18.01\n",
            "\n",
            "VIX daily: 2000-01-03 → 2025-11-05 | NaN: 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Load VIX (CBOE) \n",
        "url = \"https://cdn.cboe.com/api/global/us_indices/daily_prices/VIX_History.csv\"\n",
        "vix = pd.read_csv(url)\n",
        "\n",
        "# 2) Standardize columns and pick the correct \"close\" column \n",
        "vix.columns = [c.strip().upper() for c in vix.columns]\n",
        "\n",
        "# candidates seen: CLOSE, VIX CLOSE, Close\n",
        "close_candidates = [\"CLOSE\", \"VIX CLOSE\", \"VIX_CLOSE\"]\n",
        "close_col = next((c for c in close_candidates if c in vix.columns), None)\n",
        "if close_col is None:\n",
        "    raise KeyError(f\"Could not find VIX close column. Available: {list(vix.columns)}\")\n",
        "\n",
        "# Build a clean VIX dataframe\n",
        "vix = vix.rename(columns={\"DATE\": \"DATE\"}).copy()\n",
        "vix[\"DATE\"] = pd.to_datetime(vix[\"DATE\"], errors=\"coerce\")\n",
        "vix[\"VIX\"] = pd.to_numeric(vix[close_col], errors=\"coerce\")\n",
        "vix = vix.dropna(subset=[\"DATE\", \"VIX\"]).sort_values(\"DATE\").set_index(\"DATE\")\n",
        "\n",
        "# 3) Reindex to your daily calendar and fill gaps \n",
        "target_idx = pd.date_range(start=merged.index.min(), end=merged.index.max(), freq=\"D\")\n",
        "vix_daily = vix.reindex(target_idx).ffill().bfill()\n",
        "vix_daily.index.name = \"DATE\"\n",
        "\n",
        "# 4) Add to main dataset safely (overwrite if exists) \n",
        "merged = merged.assign(VIX=vix_daily[\"VIX\"])\n",
        "\n",
        "# 5) Inspect \n",
        "print(merged[[\"VIX\"]].head(10))\n",
        "print(merged[[\"VIX\"]].tail(10))\n",
        "print(f\"\\nVIX daily: {merged.index.min().date()} → {merged.index.max().date()} | NaN: {merged['VIX'].isna().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO-L8bPlQJl8"
      },
      "source": [
        "## Brent Oil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "gAtCO6kdQLKJ",
        "outputId": "7b7f51ff-c739-4fdd-a925-0bb675c997d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows retrieved: 9,729\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>brent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1987-05-20</td>\n",
              "      <td>18.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1987-05-21</td>\n",
              "      <td>18.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1987-05-22</td>\n",
              "      <td>18.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1987-05-25</td>\n",
              "      <td>18.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1987-05-26</td>\n",
              "      <td>18.63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date  brent\n",
              "0 1987-05-20  18.63\n",
              "1 1987-05-21  18.45\n",
              "2 1987-05-22  18.55\n",
              "3 1987-05-25  18.60\n",
              "4 1987-05-26  18.63"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>brent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9724</th>\n",
              "      <td>2025-09-16</td>\n",
              "      <td>69.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9725</th>\n",
              "      <td>2025-09-17</td>\n",
              "      <td>69.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9726</th>\n",
              "      <td>2025-09-18</td>\n",
              "      <td>67.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9727</th>\n",
              "      <td>2025-09-19</td>\n",
              "      <td>67.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9728</th>\n",
              "      <td>2025-09-22</td>\n",
              "      <td>66.87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  brent\n",
              "9724 2025-09-16  69.69\n",
              "9725 2025-09-17  69.19\n",
              "9726 2025-09-18  67.83\n",
              "9727 2025-09-19  67.05\n",
              "9728 2025-09-22  66.87"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip -q install pandas requests\n",
        "\n",
        "# Packages \n",
        "import io\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# 1) Define API endpoint and authentication \n",
        "APP_TOKEN = \"laCqAPM9Wo1SggEqlGFBAdssN\"  # X-App-Token (public)\n",
        "CSV_ENDPOINT = \"https://agtransport.usda.gov/api/v3/views/b3w8-gxpm/query.csv\"\n",
        "\n",
        "# 2) Define time range (from 1999 to current UTC date) \n",
        "date_from = \"1999-01-01T00:00:00.000\"\n",
        "date_to   = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT23:59:59.999\")\n",
        "\n",
        "# 3) Request parameters \n",
        "params = {\n",
        "    \"select\": \"date, brent\",                   # only these fields\n",
        "    \"where\": f\"date between '{date_from}' and '{date_to}'\",\n",
        "    \"order\": \"date ASC\",\n",
        "}\n",
        "headers = {\"X-App-Token\": APP_TOKEN}\n",
        "\n",
        "# 4) Download CSV \n",
        "resp = requests.get(CSV_ENDPOINT, headers=headers, params=params, timeout=60)\n",
        "resp.raise_for_status()\n",
        "\n",
        "# 5) Load into pandas \n",
        "df = pd.read_csv(io.BytesIO(resp.content))\n",
        "\n",
        "# 6) Clean data types \n",
        "df[\"date\"]  = pd.to_datetime(df[\"date\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
        "df[\"brent\"] = pd.to_numeric(df[\"brent\"], errors=\"coerce\")\n",
        "\n",
        "# Keep only the relevant columns\n",
        "df = df[[\"date\", \"brent\"]]\n",
        "\n",
        "# 7) Inspect\n",
        "print(f\"Rows retrieved: {len(df):,}\")\n",
        "display(df.head(5))\n",
        "display(df.tail(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "JcCds90racOT",
        "outputId": "0c8bc149-673a-43f8-e868-e200101dfbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing days before ffill: 4,277\n",
            "Missing days after ffill: 0\n",
            "Days filled by ffill: 4,277\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>brent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1987-05-20</td>\n",
              "      <td>18.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1987-05-21</td>\n",
              "      <td>18.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1987-05-22</td>\n",
              "      <td>18.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1987-05-23</td>\n",
              "      <td>18.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1987-05-24</td>\n",
              "      <td>18.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date  brent\n",
              "0 1987-05-20  18.63\n",
              "1 1987-05-21  18.45\n",
              "2 1987-05-22  18.55\n",
              "3 1987-05-23  18.55\n",
              "4 1987-05-24  18.55"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>brent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14001</th>\n",
              "      <td>2025-09-18</td>\n",
              "      <td>67.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14002</th>\n",
              "      <td>2025-09-19</td>\n",
              "      <td>67.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14003</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>67.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14004</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>67.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14005</th>\n",
              "      <td>2025-09-22</td>\n",
              "      <td>66.87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  brent\n",
              "14001 2025-09-18  67.83\n",
              "14002 2025-09-19  67.05\n",
              "14003 2025-09-20  67.05\n",
              "14004 2025-09-21  67.05\n",
              "14005 2025-09-22  66.87"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assumes df contains columns 'date' (datetime) and 'brent' (float)\n",
        "df_ff = df.copy().sort_values(\"date\").set_index(\"date\")\n",
        "\n",
        "# Create full daily index from first to last available date\n",
        "full_idx = pd.date_range(df_ff.index.min(), df_ff.index.max(), freq=\"D\")\n",
        "\n",
        "# Reindex to daily frequency (NaN where prices are missing)\n",
        "df_daily = df_ff.reindex(full_idx)\n",
        "\n",
        "# Count missing values before filling\n",
        "missing_before = df_daily[\"brent\"].isna().sum()\n",
        "\n",
        "# Forward-fill (does not fill before the first observation)\n",
        "df_daily[\"brent\"] = df_daily[\"brent\"].ffill()\n",
        "\n",
        "# Optionally drop leading NaNs if the series starts with gaps\n",
        "df_daily = df_daily[df_daily[\"brent\"].notna()]\n",
        "\n",
        "missing_after = df_daily[\"brent\"].isna().sum()\n",
        "filled_days = missing_before - missing_after\n",
        "\n",
        "# Convert index back to column\n",
        "df_daily = df_daily.rename_axis(\"date\").reset_index()\n",
        "\n",
        "# Inspect \n",
        "print(f\"Missing days before ffill: {missing_before:,}\")\n",
        "print(f\"Missing days after ffill: {missing_after:,}\")\n",
        "print(f\"Days filled by ffill: {filled_days:,}\")\n",
        "\n",
        "display(df_daily.head(5))\n",
        "display(df_daily.tail(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISZOGSFt32GM"
      },
      "source": [
        "## StoxEurope \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqebKVDI3_gI",
        "outputId": "a8057a9d-66f8-406d-c77d-ac8f5256e8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN count in StoxEurope: 0\n",
            "Date range: 1998-07-17 → 2025-09-26\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StoxEurope</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1998-07-17 18:00:00</th>\n",
              "      <td>313.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-20 18:00:00</th>\n",
              "      <td>315.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-21 18:00:00</th>\n",
              "      <td>313.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-22 18:00:00</th>\n",
              "      <td>308.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-23 18:00:00</th>\n",
              "      <td>307.42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     StoxEurope\n",
              "Date                           \n",
              "1998-07-17 18:00:00      313.83\n",
              "1998-07-20 18:00:00      315.00\n",
              "1998-07-21 18:00:00      313.52\n",
              "1998-07-22 18:00:00      308.13\n",
              "1998-07-23 18:00:00      307.42"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StoxEurope</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-09-22 18:00:00</th>\n",
              "      <td>553.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-23 18:00:00</th>\n",
              "      <td>554.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-24 18:00:00</th>\n",
              "      <td>553.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-25 18:00:00</th>\n",
              "      <td>550.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-26 18:00:00</th>\n",
              "      <td>554.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     StoxEurope\n",
              "Date                           \n",
              "2025-09-22 18:00:00      553.40\n",
              "2025-09-23 18:00:00      554.95\n",
              "2025-09-24 18:00:00      553.88\n",
              "2025-09-25 18:00:00      550.22\n",
              "2025-09-26 18:00:00      554.52"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Load CSV directly from GitHub\n",
        "URL = \"https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/refs/heads/main/Variables/StoxEurope/StoxxEuro600.csv\"\n",
        "\n",
        "# Read as raw text to ensure full control during cleaning\n",
        "raw = pd.read_csv(URL, sep=\",\", dtype=str, encoding=\"utf-8\")\n",
        "\n",
        "# 2) Clean column names\n",
        "raw.columns = raw.columns.str.strip()\n",
        "\n",
        "# 3) Parse 'Date' column (format: dd.mm.yyyy kl. HH.MM.SS)\n",
        "dt = raw[\"Date\"].astype(str).str.replace(\" kl. \", \" \", regex=False)\n",
        "date = pd.to_datetime(dt, format=\"%d.%m.%Y %H.%M.%S\", errors=\"coerce\")\n",
        "\n",
        "# 4) Clean 'Close' values (convert from European format to float) \n",
        "vals = (\n",
        "    raw[\"Close\"]\n",
        "    .astype(str)\n",
        "    .str.replace(\"\\u00A0\", \"\", regex=False)  # remove non-breaking space\n",
        "    .str.replace(\" \", \"\", regex=False)       # remove normal spaces\n",
        "    .str.replace(\",\", \".\", regex=False)      # replace comma with dot\n",
        "    .replace({\"\": None})\n",
        ")\n",
        "stox = pd.to_numeric(vals, errors=\"coerce\")\n",
        "\n",
        "# 5) Combine and sort \n",
        "df = (\n",
        "    pd.DataFrame({\"Date\": date, \"StoxEurope\": stox})\n",
        "      .sort_values(\"Date\")\n",
        "      .dropna(subset=[\"Date\"])\n",
        "      .set_index(\"Date\")\n",
        ")\n",
        "\n",
        "# 6) Inspect \n",
        "print(\"NaN count in StoxEurope:\", df[\"StoxEurope\"].isna().sum())\n",
        "print(\"Date range:\", df.index.min().date(), \"→\", df.index.max().date())\n",
        "display(df.head(5))\n",
        "display(df.tail(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVboSKNJ4wS_",
        "outputId": "9d825f94-3601-4013-d2cb-9d9d231e6390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values after ffill: 0\n",
            "Date range: 1998-07-17 → 2025-09-26\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StoxEurope</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1998-07-17 18:00:00</th>\n",
              "      <td>313.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-20 18:00:00</th>\n",
              "      <td>315.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-21 18:00:00</th>\n",
              "      <td>313.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-22 18:00:00</th>\n",
              "      <td>308.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-23 18:00:00</th>\n",
              "      <td>307.42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     StoxEurope\n",
              "Date                           \n",
              "1998-07-17 18:00:00      313.83\n",
              "1998-07-20 18:00:00      315.00\n",
              "1998-07-21 18:00:00      313.52\n",
              "1998-07-22 18:00:00      308.13\n",
              "1998-07-23 18:00:00      307.42"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StoxEurope</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-09-22 18:00:00</th>\n",
              "      <td>553.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-23 18:00:00</th>\n",
              "      <td>554.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-24 18:00:00</th>\n",
              "      <td>553.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-25 18:00:00</th>\n",
              "      <td>550.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-26 18:00:00</th>\n",
              "      <td>554.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     StoxEurope\n",
              "Date                           \n",
              "2025-09-22 18:00:00      553.40\n",
              "2025-09-23 18:00:00      554.95\n",
              "2025-09-24 18:00:00      553.88\n",
              "2025-09-25 18:00:00      550.22\n",
              "2025-09-26 18:00:00      554.52"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Create business-day index (weekdays only) with 18:00 timestamp\n",
        "start = df.index.min().normalize()\n",
        "end = df.index.max().normalize()\n",
        "bidx = pd.bdate_range(start=start, end=end, freq=\"B\") + pd.Timedelta(hours=18)\n",
        "\n",
        "# 2) Reindex to business days and forward-fill missing values\n",
        "df_ffill = df.reindex(bidx).ffill()\n",
        "df_ffill.index.name = \"Date\"\n",
        "\n",
        "# 3) Inspect result\n",
        "print(\"Missing values after ffill:\", df_ffill[\"StoxEurope\"].isna().sum())\n",
        "print(\"Date range:\", df_ffill.index.min().date(), \"→\", df_ffill.index.max().date())\n",
        "display(df_ffill.head(5))\n",
        "display(df_ffill.tail(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLaQA3BW5xtg"
      },
      "source": [
        "## S&P500\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing after ffill: 0\n",
            "Period: 1996-11-18 → 2025-09-26\n",
            "             Close\n",
            "Date              \n",
            "1996-11-18  737.02\n",
            "1996-11-19  742.16\n",
            "1996-11-20  742.16\n",
            "1996-11-21  742.72\n",
            "1996-11-22  748.70\n",
            "              Close\n",
            "Date               \n",
            "2025-09-22  6693.75\n",
            "2025-09-23  6656.92\n",
            "2025-09-24  6637.97\n",
            "2025-09-25  6604.72\n",
            "2025-09-26  6643.70\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Read CSV directly from GitHub \n",
        "url = \"https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/refs/heads/main/Variables/S%26P500/S%26P.csv\" \n",
        "df = pd.read_csv(url, sep=\",\", encoding=\"utf-8\", names=[\"Date\", \"Close\"], header=0)\n",
        "\n",
        "# 2) Clean and convert date \n",
        "df[\"Date\"] = (\n",
        "    df[\"Date\"]\n",
        "    .astype(str)\n",
        "    .str.replace(\"kl.\", \"\", regex=False)\n",
        "    .str.replace(\"kl\", \"\", regex=False)\n",
        "    .str.strip()\n",
        ")\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d.%m.%Y %H.%M.%S\", errors=\"coerce\")\n",
        "\n",
        "# 3) Clean and convert price \n",
        "df[\"Close\"] = (\n",
        "    df[\"Close\"]\n",
        "    .astype(str)\n",
        "    .str.replace('\"', '', regex=False)\n",
        "    .str.replace(\",\", \".\", regex=False)\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# 4) Drop missing and set index \n",
        "df = df.dropna(subset=[\"Date\", \"Close\"]).sort_values(\"Date\").set_index(\"Date\")\n",
        "\n",
        "# 5) Normalize to daily business days and forward-fill \n",
        "df.index = df.index.normalize()\n",
        "bidx = pd.bdate_range(start=df.index.min(), end=df.index.max(), freq=\"B\")\n",
        "df_sp_ffill = df.reindex(bidx).ffill()\n",
        "df_sp_ffill.index.name = \"Date\"\n",
        "\n",
        "# 6) Inspect result \n",
        "print(\"Missing after ffill:\", df_sp_ffill[\"Close\"].isna().sum())\n",
        "print(\"Period:\", df_sp_ffill.index.min().date(), \"→\", df_sp_ffill.index.max().date())\n",
        "print(df_sp_ffill.head(5))\n",
        "print(df_sp_ffill.tail(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OSEBX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing after ffill: 0\n",
            "Period: 1999-12-30 → 2025-10-03\n",
            "            OSEBX\n",
            "Date             \n",
            "1999-12-30  189.8\n",
            "1999-12-31  189.8\n",
            "2000-01-03  192.7\n",
            "2000-01-04  185.7\n",
            "2000-01-05  180.6\n",
            "             OSEBX\n",
            "Date              \n",
            "2025-09-29  1657.7\n",
            "2025-09-30  1644.6\n",
            "2025-10-01  1657.7\n",
            "2025-10-02  1650.5\n",
            "2025-10-03  1659.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Read CSV (semicolon-separated; first two lines are metadata-like, so we parse generically)\n",
        "url = \"https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/refs/heads/main/Variables/OSEBX/OSEBX_Daily.csv\"\n",
        "\n",
        "raw = pd.read_csv(\n",
        "    url,\n",
        "    sep=\";\",\n",
        "    header=None,\n",
        "    names=[\"Date\", \"OSEBX\"],\n",
        "    engine=\"python\",\n",
        "    dtype=str\n",
        ")\n",
        "\n",
        "# 2) Keep only proper date rows (dd.mm.yyyy), then parse\n",
        "raw = raw[raw[\"Date\"].str.match(r\"\\d{2}\\.\\d{2}\\.\\d{4}$\", na=False)].copy()\n",
        "raw[\"Date\"] = pd.to_datetime(raw[\"Date\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
        "\n",
        "# 3) Clean numeric values (comma decimals, NBSP)\n",
        "raw[\"OSEBX\"] = (\n",
        "    raw[\"OSEBX\"].astype(str)\n",
        "        .str.replace(\"\\u00A0\", \"\", regex=False)\n",
        "        .str.replace(\",\", \".\", regex=False)\n",
        "        .astype(float)\n",
        ")\n",
        "\n",
        "# 4) Index and forward-fill to business days\n",
        "df = (raw.dropna(subset=[\"Date\", \"OSEBX\"])\n",
        "          .sort_values(\"Date\")\n",
        "          .set_index(\"Date\"))\n",
        "\n",
        "bidx = pd.bdate_range(df.index.min(), df.index.max(), freq=\"B\")\n",
        "df_osebx_ffill = df.reindex(bidx).ffill()\n",
        "df_osebx_ffill.index.name = \"Date\"\n",
        "\n",
        "# 5) Inspect\n",
        "print(\"Missing after ffill:\", df_osebx_ffill[\"OSEBX\"].isna().sum())\n",
        "print(\"Period:\", df_osebx_ffill.index.min().date(), \"→\", df_osebx_ffill.index.max().date())\n",
        "print(df_osebx_ffill.head(5))\n",
        "print(df_osebx_ffill.tail(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OBX Energy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing after ffill: 0\n",
            "Period: 1999-12-30 → 2025-10-03\n",
            "            OBX_Energy\n",
            "Date                  \n",
            "1999-12-30     149.695\n",
            "1999-12-31     149.695\n",
            "2000-01-03     153.497\n",
            "2000-01-04     147.188\n",
            "2000-01-05     142.761\n",
            "            OBX_Energy\n",
            "Date                  \n",
            "2025-09-29     1472.79\n",
            "2025-09-30     1437.21\n",
            "2025-10-01     1449.07\n",
            "2025-10-02     1452.39\n",
            "2025-10-03     1457.35\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Read CSV (semicolon-separated; skip metadata lines)\n",
        "url = \"https://raw.githubusercontent.com/bredeespelid/Data_MasterOppgave/refs/heads/main/Variables/OSEBX/OBX_EnergyDaily.csv\"\n",
        "\n",
        "raw = pd.read_csv(\n",
        "    url,\n",
        "    sep=\";\",\n",
        "    header=None,\n",
        "    names=[\"Date\", \"OBX_Energy\"],\n",
        "    engine=\"python\",\n",
        "    dtype=str\n",
        ")\n",
        "\n",
        "# 2) Keep only proper date rows (dd.mm.yyyy) and parse\n",
        "raw = raw[raw[\"Date\"].str.match(r\"\\d{2}\\.\\d{2}\\.\\d{4}$\", na=False)].copy()\n",
        "raw[\"Date\"] = pd.to_datetime(raw[\"Date\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
        "\n",
        "# 3) Clean numeric column (comma decimals, NBSP)\n",
        "raw[\"OBX_Energy\"] = (\n",
        "    raw[\"OBX_Energy\"].astype(str)\n",
        "        .str.replace(\"\\u00A0\", \"\", regex=False)\n",
        "        .str.replace(\",\", \".\", regex=False)\n",
        "        .astype(float)\n",
        ")\n",
        "\n",
        "# 4) Index and forward-fill to business days\n",
        "df = (raw.dropna(subset=[\"Date\", \"OBX_Energy\"])\n",
        "          .sort_values(\"Date\")\n",
        "          .set_index(\"Date\"))\n",
        "\n",
        "bidx = pd.bdate_range(df.index.min(), df.index.max(), freq=\"B\")\n",
        "df_OBX_Energy_ffill = df.reindex(bidx).ffill()\n",
        "df_OBX_Energy_ffill.index.name = \"Date\"\n",
        "\n",
        "# 5) Inspect\n",
        "print(\"Missing after ffill:\", df_OBX_Energy_ffill[\"OBX_Energy\"].isna().sum())\n",
        "print(\"Period:\", df_OBX_Energy_ffill.index.min().date(), \"→\", df_OBX_Energy_ffill.index.max().date())\n",
        "print(df_OBX_Energy_ffill.head(5))\n",
        "print(df_OBX_Energy_ffill.tail(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYUa4qAfajBj"
      },
      "source": [
        "# Variables Combined Daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            EUR_NOK         Q      d_pi  dI_t  Brent    VIX  StoxEurope  \\\n",
            "DATE                                                                      \n",
            "2000-01-31   8.0825  2.030652  0.001817  1.75  27.08  24.95      360.93   \n",
            "2000-02-01   8.0730  2.027659  0.001817  1.75  27.35  23.45      366.71   \n",
            "2000-02-02   8.0175  2.020760  0.001817  1.75  27.15  23.12      371.34   \n",
            "2000-02-03   8.0475  2.024495  0.001817  1.75  27.60  22.01      376.29   \n",
            "2000-02-04   8.0830  2.028897  0.001817  1.75  27.48  21.54      377.37   \n",
            "2000-02-05   8.0830  2.028897  0.001817  1.75  27.48  21.54      377.37   \n",
            "2000-02-06   8.0830  2.028897  0.001817  1.75  27.48  21.54      377.37   \n",
            "2000-02-07   8.0590  2.025923  0.001817  1.75  27.94  22.79      374.20   \n",
            "2000-02-08   8.0720  2.027535  0.001817  1.75  27.61  21.25      382.38   \n",
            "2000-02-09   8.0825  2.028835  0.001817  1.75  27.44  22.90      382.35   \n",
            "2000-02-10   8.0695  2.027225  0.001817  1.75  27.32  23.07      381.61   \n",
            "2000-02-11   8.0395  2.023500  0.001817  1.75  27.82  24.42      381.41   \n",
            "\n",
            "              SP500  OSEBX  OBX_Energy  \n",
            "DATE                                    \n",
            "2000-01-31  1394.46  184.5     154.564  \n",
            "2000-02-01  1409.28  184.2     155.366  \n",
            "2000-02-02  1409.12  186.6     158.879  \n",
            "2000-02-03  1424.96  191.2     157.996  \n",
            "2000-02-04  1424.37  191.6     155.446  \n",
            "2000-02-05  1424.37  191.6     155.446  \n",
            "2000-02-06  1424.37  191.6     155.446  \n",
            "2000-02-07  1424.14  190.6     152.294  \n",
            "2000-02-08  1441.39  192.2     152.794  \n",
            "2000-02-09  1411.86  189.6     150.331  \n",
            "2000-02-10  1416.84  190.8     152.374  \n",
            "2000-02-11  1387.11  191.3     156.355  \n",
            "            EUR_NOK         Q      d_pi  dI_t  Brent    VIX  StoxEurope  \\\n",
            "DATE                                                                      \n",
            "2025-10-25  11.6185  2.419237 -0.002084   2.0  66.87  16.37      554.52   \n",
            "2025-10-26  11.6185  2.419237 -0.002084   2.0  66.87  16.37      554.52   \n",
            "2025-10-27  11.6320  2.420398 -0.002084   2.0  66.87  15.79      554.52   \n",
            "2025-10-28  11.6335  2.420527 -0.002084   2.0  66.87  16.42      554.52   \n",
            "2025-10-29  11.6385  2.420957 -0.002084   2.0  66.87  16.92      554.52   \n",
            "2025-10-30  11.6648  2.423214 -0.002084   2.0  66.87  16.91      554.52   \n",
            "2025-10-31  11.6485  2.421816 -0.002084   2.0  66.87  17.44      554.52   \n",
            "2025-11-01  11.6485  2.421816  0.000000   2.0  66.87  17.44      554.52   \n",
            "2025-11-02  11.6485  2.421816  0.000000   2.0  66.87  17.44      554.52   \n",
            "2025-11-03  11.6480  2.421773  0.000000   2.0  66.87  17.17      554.52   \n",
            "2025-11-04  11.7265  2.428490  0.000000   2.0  66.87  19.00      554.52   \n",
            "2025-11-05  11.7490  2.430406  0.000000   2.0  66.87  18.01      554.52   \n",
            "\n",
            "             SP500   OSEBX  OBX_Energy  \n",
            "DATE                                    \n",
            "2025-10-25  6643.7  1659.3     1457.35  \n",
            "2025-10-26  6643.7  1659.3     1457.35  \n",
            "2025-10-27  6643.7  1659.3     1457.35  \n",
            "2025-10-28  6643.7  1659.3     1457.35  \n",
            "2025-10-29  6643.7  1659.3     1457.35  \n",
            "2025-10-30  6643.7  1659.3     1457.35  \n",
            "2025-10-31  6643.7  1659.3     1457.35  \n",
            "2025-11-01  6643.7  1659.3     1457.35  \n",
            "2025-11-02  6643.7  1659.3     1457.35  \n",
            "2025-11-03  6643.7  1659.3     1457.35  \n",
            "2025-11-04  6643.7  1659.3     1457.35  \n",
            "2025-11-05  6643.7  1659.3     1457.35  \n",
            "\n",
            "Total rows: 9,411 | Period: 2000-01-31 → 2025-11-05\n",
            "NaN in Brent: 0\n",
            "NaN in VIX: 0\n",
            "NaN in StoxEurope: 0\n",
            "NaN in SP500: 0\n",
            "NaN in OSEBX: 0\n",
            "NaN in OBX_Energy: 0\n",
            "\n",
            "Saved: variables_daily.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Base: endogenous features\n",
        "\n",
        "base = final_with_rates.copy()\n",
        "# Make sure the index is Date (no time) and sorted\n",
        "base.index = pd.to_datetime(base.index, errors=\"coerce\").normalize()\n",
        "base = base.sort_index()\n",
        "\n",
        "\n",
        "# 2) Small helper: normalize any source to one column\n",
        "\n",
        "def normalize_one(\n",
        "    df,\n",
        "    target_name: str,\n",
        "    index_col: str | None = None,\n",
        "    prefer: list[str] | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    - Ensures a DatetimeIndex normalized to date-only.\n",
        "    - Picks a single value column (prefer these names if present, else first numeric, else first column).\n",
        "    - Renames that column -> `target_name`.\n",
        "    - Returns a one-column, date-indexed DataFrame.\n",
        "    \"\"\"\n",
        "    x = df.copy()\n",
        "\n",
        "    # Ensure we have a DatetimeIndex\n",
        "    if index_col is not None:\n",
        "        if index_col not in x.columns:\n",
        "            raise KeyError(f\"{target_name}: index_col '{index_col}' not found in {list(x.columns)}\")\n",
        "        x[index_col] = pd.to_datetime(x[index_col], errors=\"coerce\")\n",
        "        x = x.dropna(subset=[index_col]).set_index(index_col)\n",
        "    else:\n",
        "        if not isinstance(x.index, pd.DatetimeIndex):\n",
        "            x.index = pd.to_datetime(x.index, errors=\"coerce\")\n",
        "        x = x.dropna(subset=[x.columns[0]])  # avoid all-NaT rows if any\n",
        "\n",
        "    # Normalize to date only (removes 18:00:00 etc.)\n",
        "    x.index = x.index.normalize()\n",
        "    x = x.sort_index()\n",
        "\n",
        "    # Choose the value column\n",
        "    cols = list(x.columns)\n",
        "    if prefer:\n",
        "        for c in prefer:\n",
        "            if c in cols:\n",
        "                val = x[[c]]\n",
        "                break\n",
        "        else:\n",
        "            val = None\n",
        "    else:\n",
        "        val = None\n",
        "\n",
        "    if val is None:\n",
        "        # try numeric-only first\n",
        "        num = x.select_dtypes(include=[\"number\"])\n",
        "        if not num.empty:\n",
        "            val = num.iloc[:, [0]]\n",
        "        else:\n",
        "            # fall back to first column\n",
        "            val = x.iloc[:, [0]]\n",
        "\n",
        "    # Finalize name\n",
        "    val.columns = [target_name]\n",
        "    return val\n",
        "\n",
        "\n",
        "# 3) Normalize each exogenous series (using vars)\n",
        "\n",
        "# VIX  \n",
        "vix_idx = normalize_one(vix_daily, \"VIX\", index_col=None, prefer=[\"VIX\", \"vix\", \"Close\", \"CLOSE\"])\n",
        "\n",
        "# Brent \n",
        "brent_idx = normalize_one(df_daily, \"Brent\", index_col=\"date\", prefer=[\"brent\", \"Brent\", \"close\", \"Close\"])\n",
        "\n",
        "# STOXX Europe 600 \n",
        "stox_idx = normalize_one(df_ffill, \"StoxEurope\", index_col=None, prefer=[\"StoxEurope\", \"Close\", \"close\"])\n",
        "\n",
        "# S&P 500 \n",
        "sp500_idx = normalize_one(df_sp_ffill, \"SP500\", index_col=None, prefer=[\"SP500\", \"Close\", \"close\"])\n",
        "\n",
        "# OSEBX \n",
        "osebx_idx = normalize_one(df_osebx_ffill, \"OSEBX\", index_col=None, prefer=[\"OSEBX\"])\n",
        "\n",
        "# OBX Energy\n",
        "obx_energy_idx = normalize_one(df_OBX_Energy_ffill, \"OBX_Energy\", index_col=None, prefer=[\"OBX_Energy\"])\n",
        "\n",
        "\n",
        "# 4) Align to base dates and join (ffill for coverage)\n",
        "\n",
        "# Reindex each to the base calendar (forward-fill where missing), then join: drop any pre-existing columns with same names first\n",
        "\n",
        "to_add = {\n",
        "    \"Brent\": brent_idx,\n",
        "    \"VIX\": vix_idx,\n",
        "    \"StoxEurope\": stox_idx,\n",
        "    \"SP500\": sp500_idx,\n",
        "    \"OSEBX\": osebx_idx,\n",
        "    \"OBX_Energy\": obx_energy_idx,\n",
        "}\n",
        "\n",
        "for name, src in to_add.items():\n",
        "    if name in base.columns:\n",
        "        base = base.drop(columns=[name])\n",
        "    aligned = src.reindex(base.index, method=\"ffill\")\n",
        "    base = base.join(aligned, how=\"left\")\n",
        "\n",
        "\n",
        "# 5) Inspect and save\n",
        "\n",
        "print(base.head(12))\n",
        "print(base.tail(12))\n",
        "print(\n",
        "    f\"\\nTotal rows: {len(base):,} | \"\n",
        "    f\"Period: {base.index.min().date()} → {base.index.max().date()}\"\n",
        ")\n",
        "for c in [\"Brent\", \"VIX\", \"StoxEurope\", \"SP500\", \"OSEBX\", \"OBX_Energy\"]:\n",
        "    if c in base.columns:\n",
        "        print(f\"NaN in {c}: {base[c].isna().sum():,}\")\n",
        "\n",
        "out_name = \"variables_daily.csv\"\n",
        "base.to_csv(out_name, index_label=\"Date\")\n",
        "print(f\"\\nSaved: {out_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Daily LOG "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K00wKG3-v4l",
        "outputId": "911919d5-3f89-4bf9-be47-0d05be2183ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            EUR_NOK     log_Q  log_d_pi  log_dI_t  log_Brent   log_VIX  \\\n",
            "Date                                                                     \n",
            "2000-01-31   8.0825  0.708357 -6.310625  0.559616   3.298795  3.216874   \n",
            "2000-02-01   8.0730  0.706882 -6.310625  0.559616   3.308717  3.154870   \n",
            "2000-02-02   8.0175  0.703474 -6.310625  0.559616   3.301377  3.140698   \n",
            "2000-02-03   8.0475  0.705320 -6.310625  0.559616   3.317816  3.091497   \n",
            "2000-02-04   8.0830  0.707492 -6.310625  0.559616   3.313458  3.069912   \n",
            "\n",
            "            log_StoxEurope  log_SP500  log_OSEBX  log_OBX_Energy  \n",
            "Date                                                              \n",
            "2000-01-31        5.888684   7.240263   5.217649        5.040608  \n",
            "2000-02-01        5.904571   7.250834   5.216022        5.045784  \n",
            "2000-02-02        5.917118   7.250721   5.228967        5.068143  \n",
            "2000-02-03        5.930360   7.261899   5.253320        5.062570  \n",
            "2000-02-04        5.933226   7.261485   5.255410        5.046298  \n",
            "            EUR_NOK     log_Q  log_d_pi  log_dI_t  log_Brent   log_VIX  \\\n",
            "Date                                                                     \n",
            "2025-11-01  11.6485  0.884518       NaN  0.693147    4.20275  2.858766   \n",
            "2025-11-02  11.6485  0.884518       NaN  0.693147    4.20275  2.858766   \n",
            "2025-11-03  11.6480  0.884500       NaN  0.693147    4.20275  2.843164   \n",
            "2025-11-04  11.7265  0.887269       NaN  0.693147    4.20275  2.944439   \n",
            "2025-11-05  11.7490  0.888058       NaN  0.693147    4.20275  2.890927   \n",
            "\n",
            "            log_StoxEurope  log_SP500  log_OSEBX  log_OBX_Energy  \n",
            "Date                                                              \n",
            "2025-11-01        6.318103   8.801424   7.414151        7.284375  \n",
            "2025-11-02        6.318103   8.801424   7.414151        7.284375  \n",
            "2025-11-03        6.318103   8.801424   7.414151        7.284375  \n",
            "2025-11-04        6.318103   8.801424   7.414151        7.284375  \n",
            "2025-11-05        6.318103   8.801424   7.414151        7.284375  \n",
            "\n",
            "Saved file: variables_daily_log.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Load daily dataset \n",
        "df = pd.read_csv(\"variables_daily.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "# 2) Copy and transform all non-target variables safely \n",
        "log_df = df.copy()\n",
        "\n",
        "for col in df.columns:\n",
        "    if col != \"EUR_NOK\":\n",
        "        log_df[f\"log_{col}\"] = np.log(df[col].where(df[col] > 0))\n",
        "\n",
        "# 3) Keep only EUR_NOK + log columns \n",
        "cols_to_keep = [\"EUR_NOK\"] + [c for c in log_df.columns if c.startswith(\"log_\")]\n",
        "log_df = log_df[cols_to_keep]\n",
        "\n",
        "# 4) Save \n",
        "log_df.to_csv(\"variables_daily_log.csv\", index_label=\"Date\")\n",
        "\n",
        "# 5) Inspect \n",
        "print(log_df.head(5))\n",
        "print(log_df.tail(5))\n",
        "print(f\"\\nSaved file: variables_daily_log.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Variables Combined Monthly "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            EUR_NOK         Q      d_pi  dI_t      Brent    VIX  StoxEurope  \\\n",
            "Date                                                                          \n",
            "2000-01-31   8.0825  2.030652  0.001817  1.75  27.080000  24.95      360.93   \n",
            "2000-02-29   8.0805  2.028587  0.001817  1.75  27.774828  23.37      386.01   \n",
            "2000-03-31   8.0885  2.030130 -0.000553  1.75  27.645161  24.11      394.10   \n",
            "2000-04-30   8.1475  2.032116  0.005282  2.00  22.970000  26.20      392.62   \n",
            "2000-05-31   8.3050  2.052451 -0.001189  2.00  27.754516  23.65      380.24   \n",
            "\n",
            "              SP500  OSEBX  OBX_Energy  \n",
            "Date                                    \n",
            "2000-01-31  1394.46  184.5     154.564  \n",
            "2000-02-29  1366.41  189.4     155.128  \n",
            "2000-03-31  1498.58  188.3     165.325  \n",
            "2000-04-30  1452.43  182.1     155.681  \n",
            "2000-05-31  1420.60  190.6     176.655  \n",
            "            EUR_NOK         Q      d_pi  dI_t      Brent    VIX  StoxEurope  \\\n",
            "Date                                                                          \n",
            "2025-07-31  11.7740  2.424328  0.001332  2.25  70.990645  16.72      546.11   \n",
            "2025-08-31  11.7465  2.430918 -0.008928  2.25  67.999032  15.36      550.14   \n",
            "2025-09-30  11.7265  2.426406  0.002808  2.00  67.119000  16.28      554.52   \n",
            "2025-10-31  11.6485  2.421816 -0.002084  2.00  66.870000  17.44      554.52   \n",
            "2025-11-30  11.7490  2.430406  0.000000  2.00  66.870000  18.01      554.52   \n",
            "\n",
            "              SP500   OSEBX  OBX_Energy  \n",
            "Date                                     \n",
            "2025-07-31  6339.39  1625.3     1502.10  \n",
            "2025-08-31  6460.26  1646.5     1462.25  \n",
            "2025-09-30  6643.70  1644.6     1437.21  \n",
            "2025-10-31  6643.70  1659.3     1457.35  \n",
            "2025-11-30  6643.70  1659.3     1457.35  \n",
            "\n",
            "Saved file: variables_monthly.csv\n",
            "Period: 2000-01-31 → 2025-11-30\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Load the daily dataset \n",
        "df = pd.read_csv(\"variables_daily.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "# 2) Define aggregation rules \n",
        "\n",
        "# Average (macro/fundamental drivers)\n",
        "avg_vars = [\"Brent\"]\n",
        "\n",
        "# Last observation of the month (financial market variables)\n",
        "last_vars = [\"VIX\", \"StoxEurope\", \"SP500\", \"OSEBX\", \"OBX_Energy\"]\n",
        "\n",
        "# Endogenous variables (already monthly, but last observation)\n",
        "endo_vars = [\"EUR_NOK\", \"Q\", \"d_pi\", \"dI_t\"]\n",
        "\n",
        "\n",
        "# 3) Build the aggregation dictionary \n",
        "agg_dict = {v: \"mean\" for v in avg_vars}\n",
        "agg_dict.update({v: \"last\" for v in last_vars})\n",
        "agg_dict.update({v: \"last\" for v in endo_vars})\n",
        "\n",
        "# 4) Resample to monthly frequency \n",
        "df_monthly = df.resample(\"M\").agg(agg_dict)\n",
        "\n",
        "# 5) Reorder columns to match the daily dataset structure \n",
        "ordered_cols = [\"EUR_NOK\", \"Q\", \"d_pi\", \"dI_t\", \"Brent\", \"VIX\", \"StoxEurope\", \"SP500\", \"OSEBX\", \"OBX_Energy\"]\n",
        "df_monthly = df_monthly[ordered_cols]\n",
        "\n",
        "# 6) Save to CSV\n",
        "df_monthly.to_csv(\"variables_monthly.csv\", index_label=\"Date\")\n",
        "\n",
        "# 7) Inspect \n",
        "print(df_monthly.head(5))\n",
        "print(df_monthly.tail(5))\n",
        "print(f\"\\nSaved file: variables_monthly.csv\")\n",
        "print(f\"Period: {df_monthly.index.min().date()} → {df_monthly.index.max().date()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monthly LOG "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            EUR_NOK     log_Q  log_d_pi  log_dI_t  log_Brent   log_VIX  \\\n",
            "Date                                                                     \n",
            "2000-01-31   8.0825  0.708357 -6.310625  0.559616   3.298795  3.216874   \n",
            "2000-02-29   8.0805  0.707340 -6.310625  0.559616   3.324130  3.151453   \n",
            "2000-03-31   8.0885  0.708100       NaN  0.559616   3.319451  3.182627   \n",
            "2000-04-30   8.1475  0.709078 -5.243479  0.693147   3.134189  3.265759   \n",
            "2000-05-31   8.3050  0.719035       NaN  0.693147   3.323399  3.163363   \n",
            "\n",
            "            log_StoxEurope  log_SP500  log_OSEBX  log_OBX_Energy  \n",
            "Date                                                              \n",
            "2000-01-31        5.888684   7.240263   5.217649        5.040608  \n",
            "2000-02-29        5.955863   7.219942   5.243861        5.044251  \n",
            "2000-03-31        5.976605   7.312273   5.238036        5.107913  \n",
            "2000-04-30        5.972842   7.280993   5.204556        5.047809  \n",
            "2000-05-31        5.940803   7.258835   5.250177        5.174199  \n",
            "            EUR_NOK     log_Q  log_d_pi  log_dI_t  log_Brent   log_VIX  \\\n",
            "Date                                                                     \n",
            "2025-07-31  11.7740  0.885555 -6.621012  0.810930   4.262548  2.816606   \n",
            "2025-08-31  11.7465  0.888269       NaN  0.810930   4.219493  2.731767   \n",
            "2025-09-30  11.7265  0.886411 -5.875298  0.693147   4.206467  2.789937   \n",
            "2025-10-31  11.6485  0.884518       NaN  0.693147   4.202750  2.858766   \n",
            "2025-11-30  11.7490  0.888058       NaN  0.693147   4.202750  2.890927   \n",
            "\n",
            "            log_StoxEurope  log_SP500  log_OSEBX  log_OBX_Energy  \n",
            "Date                                                              \n",
            "2025-07-31        6.302820   8.754538   7.393448        7.314619  \n",
            "2025-08-31        6.310173   8.773425   7.406407        7.287732  \n",
            "2025-09-30        6.318103   8.801424   7.405252        7.270459  \n",
            "2025-10-31        6.318103   8.801424   7.414151        7.284375  \n",
            "2025-11-30        6.318103   8.801424   7.414151        7.284375  \n",
            "\n",
            "Saved file: variables_monthly_log.csv\n",
            "Columns: ['EUR_NOK', 'log_Q', 'log_d_pi', 'log_dI_t', 'log_Brent', 'log_VIX', 'log_StoxEurope', 'log_SP500', 'log_OSEBX', 'log_OBX_Energy']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Load the monthly dataset \n",
        "df_monthly = pd.read_csv(\"variables_monthly.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
        "\n",
        "# 2) Create a copy for log transformation \n",
        "df_monthly_log = df_monthly.copy()\n",
        "\n",
        "# 3) Define which variables to log (exclude EUR_NOK) \n",
        "log_vars = [c for c in df_monthly_log.columns if c != \"EUR_NOK\"]\n",
        "\n",
        "# 4) Convert to numeric and apply natural log (only positive values)\n",
        "df_monthly_log[log_vars] = df_monthly_log[log_vars].apply(pd.to_numeric, errors=\"coerce\")\n",
        "df_monthly_log[log_vars] = np.log(df_monthly_log[log_vars].where(df_monthly_log[log_vars] > 0))\n",
        "\n",
        "# 5) Rename logged columns with prefix 'log_' \n",
        "df_monthly_log.rename(columns={col: f\"log_{col}\" for col in log_vars}, inplace=True)\n",
        "\n",
        "# 6) Save to CSV \n",
        "out_name = \"variables_monthly_log.csv\"\n",
        "df_monthly_log.to_csv(out_name, index_label=\"Date\")\n",
        "\n",
        "# 7) Inspect\n",
        "print(df_monthly_log.head(5))\n",
        "print(df_monthly_log.tail(5))\n",
        "print(f\"\\nSaved file: {out_name}\")\n",
        "print(f\"Columns: {list(df_monthly_log.columns)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
